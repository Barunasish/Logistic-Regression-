{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80luR_XCxZqC"
      },
      "outputs": [],
      "source": [
        "##Question 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "\"\"\"\n",
        "Answer: Logistic regression predicts the likelihood of a categorical outcome, such as a yes/no choice, whereas linear regression predicts a continuous numerical value.\n",
        "The main difference is in their applications: linear regression is used to predict quantities, whereas logistic regression is used to predict categories.\n",
        "Logistic regression employs a sigmoid (S-shaped) function to convert the output into a probability between 0 and 1,\n",
        "whereas linear regression employs a linear equation and the least squares approach to determine the best fit line.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Answer: The Sigmoid (or logistic) function in logistic regression is primarily responsible for converting the model's linear output into a probability value between 0 and 1.\n",
        "This \"S-shaped\" curve condenses any real-valued input into a range appropriate for representing the probability of a binary result, which is required for classification tasks,\n",
        "allowing the model to output the likelihood of an event occurring.\n",
        "Logistic regression initially computes a weighted sum of the input features plus a bias factor, yielding a continuous value (let us call it z).\n",
        "The z value is then sent via the Sigmoid function, defined as g(z) = 1 / (1 + e^(-z)).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x4wCGo92y3Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "\"\"\"\n",
        "Answer: Regularisation in Logistic Regression is a strategy for preventing overfitting by imposing a penalty on the model's cost function, discouraging excessive coefficient values.\n",
        "This penalty aids the model in achieving a balance between fitting the training data and generalising successfully to fresh, untested data.It is required because, without it,\n",
        "particularly with numerous features,the logistic regression model may become too complex and learn the noise in the training data,\n",
        "resulting in poor performance in future predictions.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vhDG6dpM0LdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "\"\"\"\n",
        "Answer: Accuracy, Precision, Recall (Sensitivity), F1-Score, and Specificity are common classification model evaluation metrics that measure various aspects of a model's performance,\n",
        "such as how frequently it is correct (accuracy), the reliability of its positive predictions (precision),its ability to find all actual positive instances (recall),\n",
        "and its ability to correctly identify negative instances (specificity).These indicators are critical for evaluating a model's strengths and limitations,\n",
        "selecting the best model for a given problem, and ensuring that it performs effectively in its intended application.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "xXVeun3I02dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR5AY7Ni2LCk",
        "outputId": "6ffe5820-2c41-4709-99e5-4f7ee6e0de55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with L2 regularization (default)\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model coefficients:\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wjitalS20Le",
        "outputId": "4123f449-241e-4f0e-fe6a-f6e968fe8b0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model coefficients:\n",
            "sepal length (cm): -0.3935\n",
            "sepal width (cm): 0.9625\n",
            "petal length (cm): -2.3751\n",
            "petal width (cm): -0.9987\n",
            "\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with one-vs-rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_test, y_pred, target_names=data.target_names)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsjABaYr3oRY",
        "outputId": "4b62bda3-a42d-48bb-fcff-74c549b5412c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.89      0.94         9\n",
            "   virginica       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', max_iter=200)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate on test set using best estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EyasFPl4I0V",
        "outputId": "c32585c4-aaa2-422d-c041-2e15e330bd55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Best cross-validation accuracy: 0.9583\n",
            "Test set accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model_scaling = LogisticRegression(max_iter=200)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with scaling:    {accuracy_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZNUIjG14dVh",
        "outputId": "8e60ad3c-c93e-4fe5-b48c-b68b5eeb44a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling:    1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "Answer: 1. Data Collection and Cleaning:Collect relevant client data such as demographics, purchase history, browsing habits, and past campaign responses.\n",
        "Missing values are handled through imputation or elimination, depending on their extent and importance.Remove duplicates and fix inconsistencies.\n",
        "Feature Engineering:Develop significant features like recency, frequency, and monetary value (RFM).Categorical variables can be encoded using either one-hot or target encoding.\n",
        "Consider interaction terms or polynomial features, if applicable.\n",
        "Train-Test Split:To maintain the class distribution, divide the dataset into training and test sets (for example, an 80/20 split) using stratified sampling.\n",
        "2. Feature Scaling:To normalise the scale of numerical features, use either StandardScaler or MinMaxScaler.Scaling is necessary for Logistic Regression to achieve faster convergence and better performance.\n",
        "Fit the scaler to the training data only, then apply the same transformation to the test dataset.\n",
        "3. Handling Class Imbalance:Because only 5% of clients react, the dataset is extremely unbalanced.\n",
        "Techniques for addressing imbalance:\n",
        "Resampling:Oversampling the minority class via methods such as SMOTE.To eliminate prejudice, consider undersampling the majority class.Combine both (for example, SMOTE and Tomek connections).\n",
        "Class Weighting:Use the class_weight='balanced' parameter in Logistic Regression to penalise misclassification of the minority class more severely.\n",
        "Anomaly Detection Perspective: Treat respondents as anomalies and use specialised approaches as needed.\n",
        "4. Model Training and Hyperparameter Tuning:Use Logistic Regression with L2 regularisation (ridge) as a baseline.Tune hyperparameters with GridSearchCV or RandomizedSearchCV and cross-validation.\n",
        "Regularisation strength C (the inverse of regularisation).Penalty type (l1, l2) if the solver supports it.Solver option (liblinear, saga, etc.).Class weight (balanced or bespoke).\n",
        "Use stratified k-fold cross-validation to keep class distribution in folds.\n",
        "5. Model Evaluation:Accuracy is a poor metric owing to imbalance.\n",
        "Use metrics to assess minority class performance, such as precision, recall, and F1-score (particularly recall to identify responses).\n",
        "ROC-AUC (Area Under the Receiver Operating Characteristic Curve).\n",
        "PR-AUC (Area Under the Precision-Recall Curve) is more useful for imbalanced data.\n",
        "A confusion matrix might help you understand false positives and false negatives.\n",
        "Consider the business impact:False negatives (missed responses) may be more costly than false positives.\n",
        "Adjust the classification threshold to meet business objectives (for example, maximise recall while maintaining acceptable precision).\n",
        "6. Deployment Considerations:Check model performance over time for data drift.\n",
        "Retrain on new data at regular intervals.Integrate model predictions into marketing workflows to create targeted campaigns.Provide stakeholders with explainability\n",
        "(for example, feature importance and coefficients).\n",
        "\n"
      ],
      "metadata": {
        "id": "87Rd0i3H4wA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}